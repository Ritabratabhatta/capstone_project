{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the model experimentation and finalization. It covers EDA, outlier treatment, transformation, training, model evaluation and comparison across models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import shutil\n",
    "\n",
    "# standard third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# impute missing values\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import KNNImputer, IterativeImputer, SimpleImputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from category_encoders import TargetEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', message=\"pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\", \n",
    "                        category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', message=\"pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\",\n",
    "                        category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard code-template imports\n",
    "from ta_lib.core.api import (\n",
    "    create_context, get_dataframe, get_feature_names_from_column_transformer, string_cleaning,\n",
    "    get_package_path, display_as_tabs, save_pipeline, load_pipeline, initialize_environment,\n",
    "    load_dataset, save_dataset, DEFAULT_ARTIFACTS_PATH\n",
    ")\n",
    "\n",
    "import ta_lib.eda.api as eda\n",
    "from xgboost import XGBRegressor\n",
    "from ta_lib.regression.api import SKLStatsmodelOLS\n",
    "from ta_lib.regression.api import RegressionComparison, RegressionReport\n",
    "import ta_lib.reports.api as reports\n",
    "from ta_lib.data_processing.api import Outlier\n",
    "\n",
    "initialize_environment(debug=False, hide_warnings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_folder = DEFAULT_ARTIFACTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = op.join('conf', 'config.yml')\n",
    "context = create_context(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Feature Engineering\n",
    "\n",
    "The focus here is the `Pipeline` and not the model. Though the model would inform the pipeline that is needed to train the model, our focus is to set it up in such a way that it can be saved/loaded, tweaked for different model choices and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Read the Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = load_dataset(context, 'train/sales/features')\n",
    "train_y = load_dataset(context, 'train/sales/target')\n",
    "print(train_X.shape, train_y.shape)\n",
    "\n",
    "test_X = load_dataset(context, 'test/sales/features')\n",
    "test_y = load_dataset(context, 'test/sales/target')\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Feature Engineering Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev NOTES**\n",
    "\n",
    "For Feature Engineering and Model Building sklearn.pipeline.Pipeline are leveraged because of the following advantages\n",
    "<details>\n",
    "    \n",
    "1. It helps in automating workflows and are easier to read and comprehend.\n",
    "2. Right Sequence can be ensured and (for example always encodes before imputing)\n",
    "3. Reproducibility is very convenient with pipelines\n",
    "4. Pipelines help you prevent data leakage in your test data\n",
    "5. Code is near implementation ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Steps in the Feature Transformation are as follows\n",
    " - Outlier Treatment\n",
    " - Encoding of Categorical Columns\n",
    " - Missing Values Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting different types of columns for transformations\n",
    "cat_columns = train_X.select_dtypes('object').columns\n",
    "num_columns = train_X.select_dtypes('number').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Handling\n",
    "- A Custom Transformer is used to handle outliers. It is not included as part of the pipeline as outliers handling are optional for test data\n",
    "- An option to either drop or cap the outliers can be passed during the transform call\n",
    "- If we want to treat outliers for some columns them we can pass cols argument to the Transformer\n",
    "- This will go into production code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_transformer = Outlier(method='mean')\n",
    "print(train_X.shape)\n",
    "train_X = outlier_transformer.fit_transform(train_X)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sample pipelines showcasing how to create column specific pipelines and integrating them overall is presented below\n",
    "\n",
    "- Commonly target encoding is done for categorical variables with too many levels.\n",
    "- We also group sparse levels. For fewer levels one hot encoding/label encoding is preferred.\n",
    "- If there is one dominant level, we can use binary encoding.\n",
    "- This will go into production code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_enc_simple_impt = Pipeline([\n",
    "    ('target_encoding', TargetEncoder(return_df=False)),\n",
    "    ('simple_impute', SimpleImputer(strategy='most_frequent')),\n",
    "])\n",
    "\n",
    "\n",
    "# NOTE: the list of transformations here are not sequential but weighted \n",
    "# (if multiple transforms are specified for a particular column)\n",
    "# for sequential transforms use a pipeline as shown above.\n",
    "features_transformer = ColumnTransformer([\n",
    "    \n",
    "    ## categorical columns\n",
    "    ('tgt_enc', TargetEncoder(return_df=False),\n",
    "     list(set(cat_columns) - set(['technology', 'functional_status', 'platforms']))),\n",
    "    \n",
    "    # NOTE: if the same column gets repeated, then they are weighed in the final output\n",
    "    # If we want a sequence of operations, then we use a pipeline but that doesen't YET support\n",
    "    # get_feature_names. \n",
    "    ('tgt_enc_sim_impt', tgt_enc_simple_impt, ['technology', 'functional_status', 'platforms']),\n",
    "        \n",
    "    ## numeric columns\n",
    "    ('med_enc', SimpleImputer(strategy='median'), num_columns),\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev notes(Encoding):**\n",
    "<details>\n",
    "\n",
    "    Some common practices followed in Categorical Feature Encoding are\n",
    "    * For categorical variables with too many levels, target encoding can be done.\n",
    "    * For fewer levels, one hot encoding can be done.\n",
    "    * If one very dominant level is observed, binary encoding can be used.\n",
    "    \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Feature analysis\n",
    "\n",
    "Using the pipeline above analyze the features and decide on additional features to add/remove from the pipeline. This section will not be part of the production code, unless input data drifts etc. are explicitly demanded in the project.\n",
    "\n",
    "Here we are primarily focused on feature selection/elimination based on business rules, prior knowledge, data analysis.\n",
    "\n",
    "**We are not building any models at this point.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we create some sample data to analyze that we assume represent the population\n",
    "- train the features transformer and do the analysis as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_X = train_X.sample(frac=0.1, random_state=context.random_seed)\n",
    "sample_y = train_y.loc[sample_X.index]\n",
    "\n",
    "sample_train_X = get_dataframe(\n",
    "    features_transformer.fit_transform(sample_X, sample_y), \n",
    "    get_feature_names_from_column_transformer(features_transformer)\n",
    ")\n",
    "\n",
    "# nothing to do for target\n",
    "sample_train_y = sample_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the features transformer on the complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = get_dataframe(\n",
    "    features_transformer.fit_transform(train_X, train_y), \n",
    "    get_feature_names_from_column_transformer(features_transformer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Univariate\n",
    "\n",
    "\n",
    "- Look at each variable independently. This is useful if your models have assumptions on the distribution and/or bounds on the features/target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = eda.get_density_plots(train_X, cols=['brand', 'condition'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the plots are html\n",
    "reports.create_report({'univariate': out}, name='feature_analysis_univariate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A report containing the above plot is available [here](https://drive.google.com/file/d/16ntqUc_zvpg0at5pTtO-ljBjw5UVGFnp/view?usp=sharing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the above plots can be generated as a single html as below. The output from this is available [here](https://drive.google.com/file/d/1vUaCcs1PJ4IYo1em9-eZIEj9WuDsnFKT/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.feature_analysis(train_X,'./feature_analysis_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Bivariate - mutual interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find columns with high correlations and drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = eda.get_correlation_table(train_X)\n",
    "out[out[\"Abs Corr Coef\"] > 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel and source_channel highly correlated. So discarding source_channel\n",
    "# brand and manufacturer are almost same so discarding manufacturer.\n",
    "# Similarly keeping sku between inventory and sku\n",
    "# Similarly keeping condition between conditions and ext_grade\n",
    "# Similarly keeping model_family between platforms, ext_model_family and model_family\n",
    "# Discarding selling price & selling cost as they are multiples of unit price/cost & quantity.\n",
    "# Discarding gp as it is the of selling price and selling cost\n",
    "# order_no, line, invoice_no & customername cannot be IDVs\n",
    "curated_columns = list(\n",
    "    set(train_X.columns.to_list()) \n",
    "    - set(['manufacturer', 'inventory_id', 'ext_grade', 'source_channel',\n",
    "           'tgt_enc_iter_impt_platforms', 'ext_model_family',\n",
    "           'order_no', 'line', 'inventory_id',\n",
    "           'gp', 'selling_price', 'selling_cost','invoice_no','customername'])\n",
    ")\n",
    "\n",
    "train_X = train_X[curated_columns]\n",
    "\n",
    "out = eda.get_correlation_table(train_X)\n",
    "out[out[\"Abs Corr Coef\"] > 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = eda.get_bivariate_plots(train_X, x_cols=['brand'], y_cols=['color'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create reports as needed\n",
    "cols = train_X.columns.to_list()\n",
    "all_plots = {}\n",
    "for ii, col1 in enumerate(cols): \n",
    "    for jj in range(ii+1, len(cols)):\n",
    "        col2 = cols[jj]\n",
    "        out = eda.get_bivariate_plots(train_X, x_cols=[col1], y_cols=[col2])\n",
    "        all_plots.update({f'{col2} vs {col1}': out})\n",
    "\n",
    "reports.create_report(all_plots, name='feature_analysis_bivariate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A report containing the bivariate plot is available [here](https://drive.google.com/file/d/1WSGT3586tY-rOmZ57xGILbmL5ll9cSVT/view?usp=sharing)\n",
    "\n",
    "Alternatively, the above plots can be generated as a single html as below. The output from this is available [here](https://drive.google.com/file/d/1A2fz_bjYv8I3iaFDT75JQSDKeJEXxCtp/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.feature_interactions(train_X,'./feature_interaction_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Key Drivers - Interaction with Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = eda.get_target_correlation(train_X, train_y, y_continuous=True)\n",
    "display_as_tabs([(k, v) for k,v in out.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y['unit_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = eda.get_feature_importances(train_X, train_y, y_continuous=True)\n",
    "display_as_tabs([(k, v) for k,v in out.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key drivers report like feature importance, bivariate plots can be obtained as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.key_drivers(train_X,train_y, './key_drivers_report.html', y_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev Notes**\n",
    "<details>\n",
    "    \n",
    "- The SHAP plots and bivariate plots in key drivers reports can be obtained by including quick=False as a parameter to key_drivers function call. \n",
    "- SHAP plots and bivariate plots often take long depending on data shape.\n",
    "- The plot with shap is present [here](https://drive.google.com/file/d/1JOTMBLiv3LEqZ-kxZz0RokW9v5UyiGva/view?usp=sharing)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "All the plots like feature analysis, interaction, key drivers can be obtained as a single plot using data exploration method as shown below. The output from this is available [here](https://drive.google.com/file/d/1209MzmSSEhiTYuPfHpaVXFXUVbkaJm0B/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.data_exploration(train_X,train_y,'./data_exploration_report.html', y_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the list of relevant columns\n",
    "save_pipeline(curated_columns, op.abspath(op.join(artifacts_folder, 'curated_columns.joblib')))\n",
    "\n",
    "# save the feature pipeline\n",
    "save_pipeline(features_transformer, op.abspath(op.join(artifacts_folder, 'features.joblib')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Modelling - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Feature Selection(Specific to Regression)\n",
    "\n",
    "- Selecting Features specific to regression\n",
    "- VIF : measure of the amount of multi-collinearity in a set of multiple regressor variables. \n",
    "- On a case to case basis VIF thresholds change. Generally 5 or 10 are acceptable levels.\n",
    "- Usually on a recursive basis when removing the most collinear variable, there can be shuffle in VIF. \n",
    "- Often this section will not be part of the production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(train_X.columns)\n",
    "vif = eda.calc_vif(train_X)\n",
    "while max(vif.VIF) > 15:\n",
    "    #removing the largest variable from VIF\n",
    "    cols.remove(vif[(vif.VIF==vif.VIF.max())].variables.tolist()[0])\n",
    "    vif = eda.calc_vif(train_X[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_vars = vif.query('VIF < 15').variables\n",
    "reg_vars = list(reg_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transformations like these can be utilised\n",
    "def _custom_data_transform(df, cols2keep=None):\n",
    "    \"\"\"Transformation to drop some columns in the data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        df - pd.DataFrame\n",
    "        cols2keep - columns to keep in the dataframe\n",
    "    \"\"\"\n",
    "    cols2keep = cols2keep or []\n",
    "    if len(cols2keep):\n",
    "        return (df\n",
    "                .select_columns(cols2keep))\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Model training pipeline\n",
    "\n",
    "- Here we focus on creating a collection of pipelines that can be used for training respective models.\n",
    "- Each model pipeline will essentially be of the form\n",
    "```\n",
    "[\n",
    "('preprocessing', preprocessing_pipeline),\n",
    "('feature_selection', feature_selection_pipeline),\n",
    "('estimator', estimator),\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 Model Pipeline Build\n",
    "\n",
    "- This will be part of the production code (training only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ppln_ols = Pipeline([\n",
    "    ('',FunctionTransformer(_custom_data_transform, kw_args={'cols2keep':reg_vars})),\n",
    "    ('estimator', SKLStatsmodelOLS())\n",
    "])\n",
    "reg_ppln_ols.fit(train_X, train_y.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ppln_ols['estimator'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 Model Evaluation(Linear Model)\n",
    "\n",
    "This will be part of the production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ppln = Pipeline([\n",
    "    ('', FunctionTransformer(_custom_data_transform, kw_args={'cols2keep':reg_vars})),\n",
    "    ('Linear Regression', SKLStatsmodelOLS())\n",
    "])\n",
    "\n",
    "test_X = get_dataframe(\n",
    "    features_transformer.transform(test_X), \n",
    "    get_feature_names_from_column_transformer(features_transformer)\n",
    ")\n",
    "test_X = test_X[curated_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_linear_report = RegressionReport(model=reg_ppln, x_train=train_X, y_train=train_y, x_test= test_X, y_test= test_y, refit=True)\n",
    "reg_linear_report.get_report(include_shap=False, file_path='regression_linear_model_report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev Notes**\n",
    "Use SHAP for variable interpretability.\n",
    "<details>\n",
    "\n",
    "    1. Use SHAP=True to generate variable interpretability plots in the report\n",
    "    2. SHAP is recommended for non parameteric models such as RF, xgboost.\n",
    "    3. However, SHAP reports are time consuming depending on no.of records and model complexity.\n",
    "    \n",
    "A sample of regerssion report with SHAP can be found [here](https://drive.google.com/file/d/18RlQTsT1ze09Cgz-qpb4ha_cvyWbN5F5/view?usp=sharing).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.6 Residual Analysis\n",
    "- After scoring the model, it is recommended to do a residual analysis to know the distribution of errors\n",
    "- we took a threshold of 30% above which it is marked as over prediction or underprediction\n",
    "- This will not be part of the production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.3\n",
    "residual_analysis = test_X.copy()\n",
    "residual_analysis['prediction'] = reg_ppln_ols.predict(test_X)\n",
    "residual_analysis['actuals'] = test_y.reset_index(drop = True).iloc[:,0].values\n",
    "residual_analysis['forecast_flag'] = 'good'\n",
    "residual_analysis.loc[((residual_analysis['prediction'] > (1+threshold) * residual_analysis['actuals'])\\\n",
    "                       & (residual_analysis['actuals']>100)),'forecast_flag'] = 'over predict'\n",
    "residual_analysis.loc[((residual_analysis['prediction'] < (1-threshold) * residual_analysis['actuals'])\\\n",
    "                       & (residual_analysis['actuals']>100)),'forecast_flag'] = 'under predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_analysis.hvplot.kde(y=\"unit_cost\",by=\"forecast_flag\", ## Grouping by Predictions\n",
    "                                width=800, height=400,\n",
    "                                alpha=0.7,\n",
    "                                ylabel=\"density\",\n",
    "                                xlabel=\"unit_cost\",\n",
    "                                title=f'unit cost(density)',legend='top_right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the above plot we can infer that the higher \"over predictions\" are happening for unit_cost > 200.\n",
    "- similarly, the higher \"under predictions\" are happening for unit_cost is zero.\n",
    "\n",
    "This can help us tune the model by a separate model for unit_cost > 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Modelling - XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1 Model training pipeline\n",
    "\n",
    "Here we focus on creating a collection of pipelines that can be used for tranining respective models.\n",
    "\n",
    "Each model pipeline will essentially be of the form\n",
    "```\n",
    "[\n",
    "('preprocessing', preprocessing_pipeline),\n",
    "('feature_selection', feature_selection_pipeline),\n",
    "('estimator', estimator),\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Model Pipeline Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find features for some decent defaults\n",
    "estimator = XGBRegressor()\n",
    "xgb_training_pipe_init = Pipeline([\n",
    "    ('XGBoost', XGBRegressor())\n",
    "])\n",
    "xgb_training_pipe_init.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the Feature Importance\n",
    "%matplotlib inline\n",
    "imp = pd.DataFrame({'importance': xgb_training_pipe_init['XGBoost'].feature_importances_})\n",
    "imp.index = train_X.columns\n",
    "imp.sort_values('importance',inplace=True)\n",
    "imp.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'condition','model_family','days_since_last_purchase','first_time_customer','sales_person', are considered to be important and in grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pipeline build based on new importance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find features for some decent defaults\n",
    "imp_features = ['model_family','sku','unit_cost','condition','brand','business_unit']\n",
    "\n",
    "estimator = XGBRegressor()\n",
    "xgb_training_pipe2 = Pipeline([\n",
    "    ('', FunctionTransformer(_custom_data_transform, kw_args={'cols2keep':imp_features})),\n",
    "    ('XGBoost', XGBRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search of the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "   'gamma':[0.03],\n",
    "   'min_child_weight':[6],\n",
    "   'learning_rate':[0.1],\n",
    "   'max_depth':[3],\n",
    "   'n_estimators':[500], \n",
    "}\n",
    "est = XGBRegressor()\n",
    "xgb_grid = GridSearchCV(est,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 4,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(train_X, train_y)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Build using the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline_final = Pipeline([\n",
    "    ('', FunctionTransformer(_custom_data_transform, kw_args={'cols2keep':imp_features})),\n",
    "    ('XGBoost', xgb_grid.best_estimator_)\n",
    "])\n",
    "xgb_pipeline_final.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree_report = RegressionReport(model=xgb_pipeline_final, x_train=train_X, y_train=train_y, x_test= test_X, y_test= test_y)\n",
    "reg_tree_report.get_report(include_shap=False, file_path='regression_tree_model_report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Regression report containing the feature importances are available [here](https://drive.google.com/file/d/1JBfL3uxPcxBfl0amweXBFmLr7CSHFBUO/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a comparison report of the  linear (vs) tree -based model  approach can be generated as follows.\n",
    "\n",
    "This code will not be part of the production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipelines = [reg_ppln, xgb_pipeline_final]\n",
    "model_comparison_report = RegressionComparison(models=model_pipelines,x=train_X, y=train_y)\n",
    "metrics = model_comparison_report.get_report(file_path='regression_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_report.performance_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A report comparing the performance, metrics between Linear model and Tree model are available [here](https://drive.google.com/file/d/1LDibiFap9K4DKME-Y0S0mtI_05lTdaJF/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev NOTES**\n",
    "<details>\n",
    "\n",
    "the above metrics are absolute nos and not %ges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are choosing LM model for pipelining. General criteria for choosing production models is:\n",
    "\n",
    "- Parametric models (aka whitebox models) such as Linear Regression are easier to explain to non-technical audience.\n",
    "- Generally these are accepted fast and adoption is quicker.\n",
    "- If the downstream calls for optimization using these models parametric models are easier to implement.\n",
    "- When accuracy is primary goal without explainability, the above two takes a backseat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
